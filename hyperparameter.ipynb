{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install wandb\nimport wandb\nwandb.login()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-21T15:03:38.282043Z","iopub.execute_input":"2024-05-21T15:03:38.282984Z","iopub.status.idle":"2024-05-21T15:03:57.132321Z","shell.execute_reply.started":"2024-05-21T15:03:38.282937Z","shell.execute_reply":"2024-05-21T15:03:57.131326Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.16.6)\nRequirement already satisfied: Click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\nRequirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.41)\nRequirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.31.0)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.45.0)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0.1)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (69.0.3)\nRequirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.4.4)\nRequirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\nRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"!pip install ultralytics\nfrom IPython import display\ndisplay.clear_output()\n\nimport ultralytics","metadata":{"execution":{"iopub.status.busy":"2024-05-21T15:03:57.134538Z","iopub.execute_input":"2024-05-21T15:03:57.135205Z","iopub.status.idle":"2024-05-21T15:04:14.544886Z","shell.execute_reply.started":"2024-05-21T15:03:57.135171Z","shell.execute_reply":"2024-05-21T15:04:14.543825Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from ultralytics import YOLO\n\nfrom IPython.display import display, Image","metadata":{"execution":{"iopub.status.busy":"2024-05-21T15:04:14.546048Z","iopub.execute_input":"2024-05-21T15:04:14.546504Z","iopub.status.idle":"2024-05-21T15:04:14.550897Z","shell.execute_reply.started":"2024-05-21T15:04:14.546478Z","shell.execute_reply":"2024-05-21T15:04:14.549966Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"!pip install roboflow\n\nfrom roboflow import Roboflow\nrf = Roboflow(api_key=\"lqigRvMBwxOG5h9OGHlq\")\nproject = rf.workspace(\"xxxxx\").project(\"yellow-ilijm\")\nversion = project.version(4)\ndataset = version.download(\"yolov8\")\n","metadata":{"execution":{"iopub.status.busy":"2024-05-21T15:04:14.552131Z","iopub.execute_input":"2024-05-21T15:04:14.552396Z","iopub.status.idle":"2024-05-21T15:04:34.887556Z","shell.execute_reply.started":"2024-05-21T15:04:14.552374Z","shell.execute_reply":"2024-05-21T15:04:34.886523Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Collecting roboflow\n  Downloading roboflow-1.1.29-py3-none-any.whl.metadata (9.3 kB)\nCollecting certifi==2023.7.22 (from roboflow)\n  Downloading certifi-2023.7.22-py3-none-any.whl.metadata (2.2 kB)\nCollecting chardet==4.0.0 (from roboflow)\n  Downloading chardet-4.0.0-py2.py3-none-any.whl.metadata (3.5 kB)\nCollecting cycler==0.10.0 (from roboflow)\n  Downloading cycler-0.10.0-py2.py3-none-any.whl.metadata (722 bytes)\nCollecting idna==2.10 (from roboflow)\n  Downloading idna-2.10-py2.py3-none-any.whl.metadata (9.1 kB)\nRequirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.10/site-packages (from roboflow) (1.4.5)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from roboflow) (3.7.5)\nRequirement already satisfied: numpy>=1.18.5 in /opt/conda/lib/python3.10/site-packages (from roboflow) (1.26.4)\nCollecting opencv-python-headless==4.8.0.74 (from roboflow)\n  Downloading opencv_python_headless-4.8.0.74-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\nRequirement already satisfied: Pillow>=7.1.2 in /opt/conda/lib/python3.10/site-packages (from roboflow) (9.5.0)\nRequirement already satisfied: python-dateutil in /opt/conda/lib/python3.10/site-packages (from roboflow) (2.9.0.post0)\nRequirement already satisfied: python-dotenv in /opt/conda/lib/python3.10/site-packages (from roboflow) (1.0.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from roboflow) (2.31.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from roboflow) (1.16.0)\nRequirement already satisfied: urllib3>=1.26.6 in /opt/conda/lib/python3.10/site-packages (from roboflow) (1.26.18)\nRequirement already satisfied: tqdm>=4.41.0 in /opt/conda/lib/python3.10/site-packages (from roboflow) (4.66.1)\nRequirement already satisfied: PyYAML>=5.3.1 in /opt/conda/lib/python3.10/site-packages (from roboflow) (6.0.1)\nRequirement already satisfied: requests-toolbelt in /opt/conda/lib/python3.10/site-packages (from roboflow) (0.10.1)\nCollecting python-magic (from roboflow)\n  Downloading python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->roboflow) (1.2.0)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->roboflow) (4.47.0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->roboflow) (21.3)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->roboflow) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->roboflow) (3.3.2)\nDownloading roboflow-1.1.29-py3-none-any.whl (74 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.9/74.9 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading certifi-2023.7.22-py3-none-any.whl (158 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.3/158.3 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\nDownloading idna-2.10-py2.py3-none-any.whl (58 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading opencv_python_headless-4.8.0.74-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\nInstalling collected packages: python-magic, opencv-python-headless, idna, cycler, chardet, certifi, roboflow\n  Attempting uninstall: opencv-python-headless\n    Found existing installation: opencv-python-headless 4.9.0.80\n    Uninstalling opencv-python-headless-4.9.0.80:\n      Successfully uninstalled opencv-python-headless-4.9.0.80\n  Attempting uninstall: idna\n    Found existing installation: idna 3.6\n    Uninstalling idna-3.6:\n      Successfully uninstalled idna-3.6\n  Attempting uninstall: cycler\n    Found existing installation: cycler 0.12.1\n    Uninstalling cycler-0.12.1:\n      Successfully uninstalled cycler-0.12.1\n  Attempting uninstall: certifi\n    Found existing installation: certifi 2024.2.2\n    Uninstalling certifi-2024.2.2:\n      Successfully uninstalled certifi-2024.2.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\njupyterlab 4.1.6 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nlibpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmomepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nosmnx 1.9.2 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\nspopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\ntensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.2.1 which is incompatible.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed certifi-2023.7.22 chardet-4.0.0 cycler-0.10.0 idna-2.10 opencv-python-headless-4.8.0.74 python-magic-0.4.27 roboflow-1.1.29\nloading Roboflow workspace...\nloading Roboflow project...\nDependency ultralytics==8.0.196 is required but found version=8.2.18, to fix: `pip install ultralytics==8.0.196`\n","output_type":"stream"},{"name":"stderr","text":"Downloading Dataset Version Zip in yellow-4 to yolov8:: 100%|██████████| 20717/20717 [00:01<00:00, 16106.43it/s]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"\nExtracting Dataset Version Zip to yellow-4 in yolov8:: 100%|██████████| 1312/1312 [00:00<00:00, 8586.42it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"%%writefile /kaggle/working/yellow-4/data.yaml\nnames:\n- yellow smoke\nnc: 1\nroboflow:\n  license: MIT\n  project: yellow-ilijm\n  url: https://universe.roboflow.com/xxxxx/yellow-ilijm/dataset/4\n  version: 4\n  workspace: xxxxx\ntest: ../test/images\ntrain: ../train/images\nval: ../valid/images","metadata":{"execution":{"iopub.status.busy":"2024-05-21T15:04:34.890537Z","iopub.execute_input":"2024-05-21T15:04:34.890838Z","iopub.status.idle":"2024-05-21T15:04:34.897629Z","shell.execute_reply.started":"2024-05-21T15:04:34.890810Z","shell.execute_reply":"2024-05-21T15:04:34.896617Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Overwriting /kaggle/working/yellow-4/data.yaml\n","output_type":"stream"}]},{"cell_type":"code","source":"sweep_config = {\n    'method': 'random' \n    }\nprint(\"Finished Setup\")","metadata":{"execution":{"iopub.status.busy":"2024-05-21T15:40:28.837104Z","iopub.execute_input":"2024-05-21T15:40:28.838068Z","iopub.status.idle":"2024-05-21T15:40:28.843169Z","shell.execute_reply.started":"2024-05-21T15:40:28.838025Z","shell.execute_reply":"2024-05-21T15:40:28.842064Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Finished Setup\n","output_type":"stream"}]},{"cell_type":"code","source":"metric = {\n    'name': 'metrics/mAP50-95(B)',\n    'goal': 'maximize'   \n    }\n\nsweep_config['metric'] = metric\nprint(\"Finished Setup\")","metadata":{"execution":{"iopub.status.busy":"2024-05-21T15:40:30.843537Z","iopub.execute_input":"2024-05-21T15:40:30.844459Z","iopub.status.idle":"2024-05-21T15:40:30.849702Z","shell.execute_reply.started":"2024-05-21T15:40:30.844424Z","shell.execute_reply":"2024-05-21T15:40:30.848667Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Finished Setup\n","output_type":"stream"}]},{"cell_type":"code","source":"parameters_dict = {\n    'epochs': {\n        'values': [5,15,25]\n    },\n    'batch': {\n        'values': [16,32]\n    },\n    'lr0': {\n\n        'distribution': 'uniform',\n        'min': 0.0005,\n        'max': 0.005\n    },\n    'lrf': {\n        # a flat distribution\n        'distribution': 'uniform',\n        'min': 0.001,\n        'max': 0.01\n    },\n}\n\nsweep_config['parameters'] = parameters_dict\nimport pprint\npprint.pprint(sweep_config)","metadata":{"execution":{"iopub.status.busy":"2024-05-21T15:46:42.270799Z","iopub.execute_input":"2024-05-21T15:46:42.271201Z","iopub.status.idle":"2024-05-21T15:46:42.278505Z","shell.execute_reply.started":"2024-05-21T15:46:42.271172Z","shell.execute_reply":"2024-05-21T15:46:42.277363Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"{'method': 'random',\n 'metric': {'goal': 'maximize', 'name': 'metrics/mAP50-95(B)'},\n 'parameters': {'batch': {'values': [16, 32]},\n                'epochs': {'values': [5, 15, 25]},\n                'lr0': {'distribution': 'uniform', 'max': 0.005, 'min': 0.0005},\n                'lrf': {'distribution': 'uniform', 'max': 0.01, 'min': 0.001}}}\n","output_type":"stream"}]},{"cell_type":"code","source":"sweep_id = wandb.sweep(sweep_config, project=\"hyper\")","metadata":{"execution":{"iopub.status.busy":"2024-05-21T15:46:45.062085Z","iopub.execute_input":"2024-05-21T15:46:45.062709Z","iopub.status.idle":"2024-05-21T15:46:45.478656Z","shell.execute_reply.started":"2024-05-21T15:46:45.062674Z","shell.execute_reply":"2024-05-21T15:46:45.477704Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"Create sweep with ID: y350t980\nSweep URL: https://wandb.ai/pirajesh1/hyper/sweeps/y350t980\n","output_type":"stream"}]},{"cell_type":"code","source":"import os","metadata":{"execution":{"iopub.status.busy":"2024-05-21T15:04:35.905285Z","iopub.execute_input":"2024-05-21T15:04:35.905579Z","iopub.status.idle":"2024-05-21T15:04:35.909965Z","shell.execute_reply.started":"2024-05-21T15:04:35.905554Z","shell.execute_reply":"2024-05-21T15:04:35.908906Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"model = YOLO('yolov8s.pt')","metadata":{"execution":{"iopub.status.busy":"2024-05-21T15:04:35.911227Z","iopub.execute_input":"2024-05-21T15:04:35.911758Z","iopub.status.idle":"2024-05-21T15:04:36.883775Z","shell.execute_reply.started":"2024-05-21T15:04:35.911726Z","shell.execute_reply":"2024-05-21T15:04:36.882755Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8s.pt to 'yolov8s.pt'...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 21.5M/21.5M [00:00<00:00, 273MB/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"def train(config=None):\n    wandb.init(config=config, tags=[\"trial3\"]) # Initialize a new W&B Run\n    config = wandb.config # Config set by Sweep Controller\n    \n    # Train function\n    results = model.train(data='/kaggle/working/yellow-4/data.yaml',\n                          epochs = config.epochs,\n                          batch = config.batch,\n                          lr0 = config.lr0,\n                          lrf = config.lrf,\n                          project = \"hyper\", imgsz = 800, plots = True)\n\n\nwandb.agent(sweep_id, train, count=10)","metadata":{"execution":{"iopub.status.busy":"2024-05-21T15:47:04.657595Z","iopub.execute_input":"2024-05-21T15:47:04.658237Z","iopub.status.idle":"2024-05-21T15:56:08.749397Z","shell.execute_reply.started":"2024-05-21T15:47:04.658204Z","shell.execute_reply":"2024-05-21T15:56:08.747970Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: vfa2n87f with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr0: 0.0008702496532952626\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlrf: 0.003926182955791735\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240521_154707-vfa2n87f</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/pirajesh1/hyper/runs/vfa2n87f' target=\"_blank\">sage-sweep-1</a></strong> to <a href='https://wandb.ai/pirajesh1/hyper' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/pirajesh1/hyper/sweeps/y350t980' target=\"_blank\">https://wandb.ai/pirajesh1/hyper/sweeps/y350t980</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/pirajesh1/hyper' target=\"_blank\">https://wandb.ai/pirajesh1/hyper</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/pirajesh1/hyper/sweeps/y350t980' target=\"_blank\">https://wandb.ai/pirajesh1/hyper/sweeps/y350t980</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/pirajesh1/hyper/runs/vfa2n87f' target=\"_blank\">https://wandb.ai/pirajesh1/hyper/runs/vfa2n87f</a>"},"metadata":{}},{"name":"stdout","text":"Ultralytics YOLOv8.2.18 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=/kaggle/working/yellow-4/data.yaml, epochs=5, time=None, patience=50, batch=16, imgsz=800, save=True, save_period=1, cache=False, device=None, workers=8, project=hyper, name=train, exist_ok=True, pretrained=True, optimizer=Adam, verbose=False, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=True, close_mosaic=10, resume=False, amp=False, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=True, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.0008702496532952626, lrf=0.003926182955791735, momentum=0.009842836455701677, weight_decay=0.007525843980226237, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=0.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=hyper/train\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n 22        [15, 18, 21]  1   2116435  ultralytics.nn.modules.head.Detect           [1, [128, 256, 512]]          \nModel summary: 225 layers, 11135987 parameters, 11135971 gradients, 28.6 GFLOPs\n\nTransferred 355/355 items from pretrained weights\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir hyper/train', view at http://localhost:6006/\nFreezing layer 'model.22.dfl.conv.weight'\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/yellow-4/train/labels.cache... 600 images, 0 backgrounds, 0 corrupt: 100%|██████████| 600/600 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","output_type":"stream"},{"name":"stderr","text":"\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/yellow-4/valid/labels.cache... 31 images, 0 backgrounds, 0 corrupt: 100%|██████████| 31/31 [00:00<?, ?it/s]\n","output_type":"stream"},{"name":"stdout","text":"Plotting labels to hyper/train/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.0008702496532952626, momentum=0.009842836455701677) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.007525843980226237), 63 bias(decay=0.0)\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\nImage sizes 800 train, 800 val\nUsing 4 dataloader workers\nLogging results to \u001b[1mhyper/train\u001b[0m\nStarting training for 5 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"        1/5      11.2G      1.599       1.43      2.028          8        800: 100%|██████████| 38/38 [00:18<00:00,  2.10it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.18it/s]","output_type":"stream"},{"name":"stdout","text":"                   all         31         32      0.709      0.781      0.883      0.592\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"        2/5      12.4G      1.626      1.495      2.053         11        800: 100%|██████████| 38/38 [00:17<00:00,  2.15it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.21it/s]","output_type":"stream"},{"name":"stdout","text":"                   all         31         32      0.734      0.844      0.842      0.509\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"        3/5      12.4G      1.648      1.457      2.033         10        800: 100%|██████████| 38/38 [00:17<00:00,  2.15it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.19it/s]","output_type":"stream"},{"name":"stdout","text":"                   all         31         32     0.0469     0.0938     0.0269    0.00708\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"        4/5      12.4G      1.582      1.427      1.983         10        800: 100%|██████████| 38/38 [00:17<00:00,  2.15it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.16it/s]","output_type":"stream"},{"name":"stdout","text":"                   all         31         32      0.769       0.73      0.914      0.593\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"        5/5      12.4G      1.526      1.336      1.948         10        800: 100%|██████████| 38/38 [00:17<00:00,  2.16it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.19it/s]","output_type":"stream"},{"name":"stdout","text":"                   all         31         32      0.924      0.759      0.933      0.653\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n5 epochs completed in 0.028 hours.\nOptimizer stripped from hyper/train/weights/last.pt, 22.6MB\nOptimizer stripped from hyper/train/weights/best.pt, 22.6MB\n\nValidating hyper/train/weights/best.pt...\nUltralytics YOLOv8.2.18 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\nModel summary (fused): 168 layers, 11125971 parameters, 0 gradients, 28.4 GFLOPs\n","output_type":"stream"},{"name":"stderr","text":"                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all         31         32      0.924      0.759      0.933      0.653\nSpeed: 0.2ms preprocess, 6.9ms inference, 0.0ms loss, 0.6ms postprocess per image\nResults saved to \u001b[1mhyper/train\u001b[0m\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='24.992 MB of 24.992 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>█▅▁▁▁</td></tr><tr><td>lr/pg1</td><td>▄▇█▄▁</td></tr><tr><td>lr/pg2</td><td>▄▇█▄▁</td></tr><tr><td>metrics/mAP50(B)</td><td>█▇▁██</td></tr><tr><td>metrics/mAP50-95(B)</td><td>▇▆▁▇█</td></tr><tr><td>metrics/precision(B)</td><td>▆▆▁▇█</td></tr><tr><td>metrics/recall(B)</td><td>▇█▁▇▇</td></tr><tr><td>model/GFLOPs</td><td>▁</td></tr><tr><td>model/parameters</td><td>▁</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>▁</td></tr><tr><td>train/box_loss</td><td>▅▇█▄▁</td></tr><tr><td>train/cls_loss</td><td>▅█▆▅▁</td></tr><tr><td>train/dfl_loss</td><td>▆█▇▃▁</td></tr><tr><td>val/box_loss</td><td>▁▂█▂▁</td></tr><tr><td>val/cls_loss</td><td>▁▁█▁▁</td></tr><tr><td>val/dfl_loss</td><td>▁▁█▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>9e-05</td></tr><tr><td>lr/pg1</td><td>9e-05</td></tr><tr><td>lr/pg2</td><td>9e-05</td></tr><tr><td>metrics/mAP50(B)</td><td>0.93266</td></tr><tr><td>metrics/mAP50-95(B)</td><td>0.65279</td></tr><tr><td>metrics/precision(B)</td><td>0.92388</td></tr><tr><td>metrics/recall(B)</td><td>0.75883</td></tr><tr><td>model/GFLOPs</td><td>28.647</td></tr><tr><td>model/parameters</td><td>11135987</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>6.723</td></tr><tr><td>train/box_loss</td><td>1.52591</td></tr><tr><td>train/cls_loss</td><td>1.33637</td></tr><tr><td>train/dfl_loss</td><td>1.94782</td></tr><tr><td>val/box_loss</td><td>1.17023</td></tr><tr><td>val/cls_loss</td><td>1.01053</td></tr><tr><td>val/dfl_loss</td><td>1.59376</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">sage-sweep-1</strong> at: <a href='https://wandb.ai/pirajesh1/hyper/runs/vfa2n87f' target=\"_blank\">https://wandb.ai/pirajesh1/hyper/runs/vfa2n87f</a><br/> View project at: <a href='https://wandb.ai/pirajesh1/hyper' target=\"_blank\">https://wandb.ai/pirajesh1/hyper</a><br/>Synced 5 W&B file(s), 17 media file(s), 5 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240521_154707-vfa2n87f/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: lgi8g89n with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr0: 0.004549234596187533\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlrf: 0.002190720953217906\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240521_154942-lgi8g89n</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/pirajesh1/hyper/runs/lgi8g89n' target=\"_blank\">noble-sweep-2</a></strong> to <a href='https://wandb.ai/pirajesh1/hyper' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/pirajesh1/hyper/sweeps/y350t980' target=\"_blank\">https://wandb.ai/pirajesh1/hyper/sweeps/y350t980</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/pirajesh1/hyper' target=\"_blank\">https://wandb.ai/pirajesh1/hyper</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/pirajesh1/hyper/sweeps/y350t980' target=\"_blank\">https://wandb.ai/pirajesh1/hyper/sweeps/y350t980</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/pirajesh1/hyper/runs/lgi8g89n' target=\"_blank\">https://wandb.ai/pirajesh1/hyper/runs/lgi8g89n</a>"},"metadata":{}},{"name":"stdout","text":"Ultralytics YOLOv8.2.18 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=/kaggle/working/yellow-4/data.yaml, epochs=5, time=None, patience=50, batch=16, imgsz=800, save=True, save_period=1, cache=False, device=None, workers=8, project=hyper, name=train, exist_ok=True, pretrained=True, optimizer=Adam, verbose=False, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=True, close_mosaic=10, resume=False, amp=False, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=True, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.004549234596187533, lrf=0.002190720953217906, momentum=0.009842836455701677, weight_decay=0.007525843980226237, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=0.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=hyper/train\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n 22        [15, 18, 21]  1   2116435  ultralytics.nn.modules.head.Detect           [1, [128, 256, 512]]          \nModel summary: 225 layers, 11135987 parameters, 11135971 gradients, 28.6 GFLOPs\n\nTransferred 355/355 items from pretrained weights\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir hyper/train', view at http://localhost:6006/\nFreezing layer 'model.22.dfl.conv.weight'\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/yellow-4/train/labels.cache... 600 images, 0 backgrounds, 0 corrupt: 100%|██████████| 600/600 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","output_type":"stream"},{"name":"stderr","text":"\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/yellow-4/valid/labels.cache... 31 images, 0 backgrounds, 0 corrupt: 100%|██████████| 31/31 [00:00<?, ?it/s]\n","output_type":"stream"},{"name":"stdout","text":"Plotting labels to hyper/train/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.004549234596187533, momentum=0.009842836455701677) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.007525843980226237), 63 bias(decay=0.0)\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\nImage sizes 800 train, 800 val\nUsing 4 dataloader workers\nLogging results to \u001b[1mhyper/train\u001b[0m\nStarting training for 5 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"        1/5      12.4G       1.77      1.757      2.178          8        800: 100%|██████████| 38/38 [00:18<00:00,  2.09it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.59it/s]","output_type":"stream"},{"name":"stdout","text":"                   all         31         32          0          0          0          0\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"        2/5      12.3G      2.211      2.462      2.674         11        800: 100%|██████████| 38/38 [00:17<00:00,  2.15it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.14it/s]","output_type":"stream"},{"name":"stdout","text":"                   all         31         32          0          0          0          0\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"        3/5      12.4G      2.102      2.328      2.516         10        800: 100%|██████████| 38/38 [00:17<00:00,  2.15it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.94it/s]","output_type":"stream"},{"name":"stdout","text":"                   all         31         32    0.00383      0.406    0.00258   0.000761\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"        4/5      12.4G      2.006       2.15       2.44         10        800: 100%|██████████| 38/38 [00:17<00:00,  2.15it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.06it/s]","output_type":"stream"},{"name":"stdout","text":"                   all         31         32       0.78      0.656      0.816      0.455\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"        5/5      12.3G      1.722      1.814      2.187         10        800: 100%|██████████| 38/38 [00:17<00:00,  2.15it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.08it/s]","output_type":"stream"},{"name":"stdout","text":"                   all         31         32      0.777      0.763      0.859       0.51\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"\n5 epochs completed in 0.029 hours.\nOptimizer stripped from hyper/train/weights/last.pt, 22.6MB\nOptimizer stripped from hyper/train/weights/best.pt, 22.6MB\n\nValidating hyper/train/weights/best.pt...\nUltralytics YOLOv8.2.18 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\nModel summary (fused): 168 layers, 11125971 parameters, 0 gradients, 28.4 GFLOPs\n","output_type":"stream"},{"name":"stderr","text":"                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.96it/s]\n","output_type":"stream"},{"name":"stdout","text":"                   all         31         32      0.777      0.763      0.859      0.509\nSpeed: 0.2ms preprocess, 6.8ms inference, 0.0ms loss, 0.7ms postprocess per image\nResults saved to \u001b[1mhyper/train\u001b[0m\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='24.958 MB of 24.958 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>█▅▁▁▁</td></tr><tr><td>lr/pg1</td><td>▄▇█▄▁</td></tr><tr><td>lr/pg2</td><td>▄▇█▄▁</td></tr><tr><td>metrics/mAP50(B)</td><td>▁▁▁██</td></tr><tr><td>metrics/mAP50-95(B)</td><td>▁▁▁▇█</td></tr><tr><td>metrics/precision(B)</td><td>▁▁▁██</td></tr><tr><td>metrics/recall(B)</td><td>▁▁▅▇█</td></tr><tr><td>model/GFLOPs</td><td>▁</td></tr><tr><td>model/parameters</td><td>▁</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>▁</td></tr><tr><td>train/box_loss</td><td>▂█▆▅▁</td></tr><tr><td>train/cls_loss</td><td>▁█▇▅▂</td></tr><tr><td>train/dfl_loss</td><td>▁█▆▅▁</td></tr><tr><td>val/box_loss</td><td>  █▂▁</td></tr><tr><td>val/cls_loss</td><td>   █▁</td></tr><tr><td>val/dfl_loss</td><td>  █▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>0.00044</td></tr><tr><td>lr/pg1</td><td>0.00044</td></tr><tr><td>lr/pg2</td><td>0.00044</td></tr><tr><td>metrics/mAP50(B)</td><td>0.85931</td></tr><tr><td>metrics/mAP50-95(B)</td><td>0.50893</td></tr><tr><td>metrics/precision(B)</td><td>0.77721</td></tr><tr><td>metrics/recall(B)</td><td>0.76335</td></tr><tr><td>model/GFLOPs</td><td>28.647</td></tr><tr><td>model/parameters</td><td>11135987</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>6.863</td></tr><tr><td>train/box_loss</td><td>1.72189</td></tr><tr><td>train/cls_loss</td><td>1.81357</td></tr><tr><td>train/dfl_loss</td><td>2.1868</td></tr><tr><td>val/box_loss</td><td>1.34593</td></tr><tr><td>val/cls_loss</td><td>1.4569</td></tr><tr><td>val/dfl_loss</td><td>1.8025</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">noble-sweep-2</strong> at: <a href='https://wandb.ai/pirajesh1/hyper/runs/lgi8g89n' target=\"_blank\">https://wandb.ai/pirajesh1/hyper/runs/lgi8g89n</a><br/> View project at: <a href='https://wandb.ai/pirajesh1/hyper' target=\"_blank\">https://wandb.ai/pirajesh1/hyper</a><br/>Synced 5 W&B file(s), 17 media file(s), 5 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240521_154942-lgi8g89n/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2hoc13oe with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr0: 0.0032476144878420417\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlrf: 0.0026193553566555327\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240521_155217-2hoc13oe</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/pirajesh1/hyper/runs/2hoc13oe' target=\"_blank\">curious-sweep-3</a></strong> to <a href='https://wandb.ai/pirajesh1/hyper' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/pirajesh1/hyper/sweeps/y350t980' target=\"_blank\">https://wandb.ai/pirajesh1/hyper/sweeps/y350t980</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/pirajesh1/hyper' target=\"_blank\">https://wandb.ai/pirajesh1/hyper</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/pirajesh1/hyper/sweeps/y350t980' target=\"_blank\">https://wandb.ai/pirajesh1/hyper/sweeps/y350t980</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/pirajesh1/hyper/runs/2hoc13oe' target=\"_blank\">https://wandb.ai/pirajesh1/hyper/runs/2hoc13oe</a>"},"metadata":{}},{"name":"stdout","text":"Ultralytics YOLOv8.2.18 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=/kaggle/working/yellow-4/data.yaml, epochs=5, time=None, patience=50, batch=32, imgsz=800, save=True, save_period=1, cache=False, device=None, workers=8, project=hyper, name=train, exist_ok=True, pretrained=True, optimizer=Adam, verbose=False, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=True, close_mosaic=10, resume=False, amp=False, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=True, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.0032476144878420417, lrf=0.0026193553566555327, momentum=0.009842836455701677, weight_decay=0.007525843980226237, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=0.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=hyper/train\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n 22        [15, 18, 21]  1   2116435  ultralytics.nn.modules.head.Detect           [1, [128, 256, 512]]          \nModel summary: 225 layers, 11135987 parameters, 11135971 gradients, 28.6 GFLOPs\n\nTransferred 355/355 items from pretrained weights\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir hyper/train', view at http://localhost:6006/\nFreezing layer 'model.22.dfl.conv.weight'\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/yellow-4/train/labels.cache... 600 images, 0 backgrounds, 0 corrupt: 100%|██████████| 600/600 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","output_type":"stream"},{"name":"stderr","text":"\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/yellow-4/valid/labels.cache... 31 images, 0 backgrounds, 0 corrupt: 100%|██████████| 31/31 [00:00<?, ?it/s]\n","output_type":"stream"},{"name":"stdout","text":"Plotting labels to hyper/train/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.0032476144878420417, momentum=0.009842836455701677) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.007525843980226237), 63 bias(decay=0.0)\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\nImage sizes 800 train, 800 val\nUsing 4 dataloader workers\nLogging results to \u001b[1mhyper/train\u001b[0m\nStarting training for 5 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/19 [00:00<?, ?it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">curious-sweep-3</strong> at: <a href='https://wandb.ai/pirajesh1/hyper/runs/2hoc13oe' target=\"_blank\">https://wandb.ai/pirajesh1/hyper/runs/2hoc13oe</a><br/> View project at: <a href='https://wandb.ai/pirajesh1/hyper' target=\"_blank\">https://wandb.ai/pirajesh1/hyper</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240521_155217-2hoc13oe/logs</code>"},"metadata":{}},{"name":"stderr","text":"Run 2hoc13oe errored:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/agents/pyagent.py\", line 308, in _run_job\n    self._function()\n  File \"/tmp/ipykernel_34/1789913246.py\", line 6, in train\n    results = model.train(data='/kaggle/working/yellow-4/data.yaml',\n  File \"/opt/conda/lib/python3.10/site-packages/ultralytics/engine/model.py\", line 674, in train\n    self.trainer.train()\n  File \"/opt/conda/lib/python3.10/site-packages/ultralytics/engine/trainer.py\", line 199, in train\n    self._do_train(world_size)\n  File \"/opt/conda/lib/python3.10/site-packages/ultralytics/engine/trainer.py\", line 371, in _do_train\n    self.loss, self.loss_items = self.model(batch)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/ultralytics/nn/tasks.py\", line 88, in forward\n    return self.loss(x, *args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/ultralytics/nn/tasks.py\", line 266, in loss\n    preds = self.forward(batch[\"img\"]) if preds is None else preds\n  File \"/opt/conda/lib/python3.10/site-packages/ultralytics/nn/tasks.py\", line 89, in forward\n    return self.predict(x, *args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/ultralytics/nn/tasks.py\", line 107, in predict\n    return self._predict_once(x, profile, visualize, embed)\n  File \"/opt/conda/lib/python3.10/site-packages/ultralytics/nn/tasks.py\", line 128, in _predict_once\n    x = m(x)  # run\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/ultralytics/nn/modules/block.py\", line 230, in forward\n    y.extend(m(y[-1]) for m in self.m)\n  File \"/opt/conda/lib/python3.10/site-packages/ultralytics/nn/modules/block.py\", line 230, in <genexpr>\n    y.extend(m(y[-1]) for m in self.m)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/ultralytics/nn/modules/block.py\", line 340, in forward\n    return x + self.cv2(self.cv1(x)) if self.add else self.cv2(self.cv1(x))\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/ultralytics/nn/modules/conv.py\", line 50, in forward\n    return self.act(self.bn(self.conv(x)))\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/conv.py\", line 460, in forward\n    return self._conv_forward(input, self.weight, self.bias)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/conv.py\", line 456, in _conv_forward\n    return F.conv2d(input, weight, bias, self.stride,\ntorch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 15.89 GiB of which 30.12 MiB is free. Process 2817 has 15.86 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 314.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 2hoc13oe errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/wandb/agents/pyagent.py\", line 308, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_34/1789913246.py\", line 6, in train\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     results = model.train(data='/kaggle/working/yellow-4/data.yaml',\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ultralytics/engine/model.py\", line 674, in train\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self.trainer.train()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ultralytics/engine/trainer.py\", line 199, in train\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._do_train(world_size)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ultralytics/engine/trainer.py\", line 371, in _do_train\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self.loss, self.loss_items = self.model(batch)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ultralytics/nn/tasks.py\", line 88, in forward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self.loss(x, *args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ultralytics/nn/tasks.py\", line 266, in loss\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     preds = self.forward(batch[\"img\"]) if preds is None else preds\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ultralytics/nn/tasks.py\", line 89, in forward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self.predict(x, *args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ultralytics/nn/tasks.py\", line 107, in predict\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._predict_once(x, profile, visualize, embed)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ultralytics/nn/tasks.py\", line 128, in _predict_once\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     x = m(x)  # run\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ultralytics/nn/modules/block.py\", line 230, in forward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     y.extend(m(y[-1]) for m in self.m)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ultralytics/nn/modules/block.py\", line 230, in <genexpr>\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     y.extend(m(y[-1]) for m in self.m)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ultralytics/nn/modules/block.py\", line 340, in forward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return x + self.cv2(self.cv1(x)) if self.add else self.cv2(self.cv1(x))\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ultralytics/nn/modules/conv.py\", line 50, in forward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self.act(self.bn(self.conv(x)))\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/conv.py\", line 460, in forward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._conv_forward(input, self.weight, self.bias)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/conv.py\", line 456, in _conv_forward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return F.conv2d(input, weight, bias, self.stride,\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 15.89 GiB of which 30.12 MiB is free. Process 2817 has 15.86 GiB memory in use. Of the allocated memory 15.17 GiB is allocated by PyTorch, and 314.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: nu1nsubh with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 25\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr0: 0.003739075196324232\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlrf: 0.001936001342953816\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240521_155304-nu1nsubh</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/pirajesh1/hyper/runs/nu1nsubh' target=\"_blank\">winter-sweep-4</a></strong> to <a href='https://wandb.ai/pirajesh1/hyper' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/pirajesh1/hyper/sweeps/y350t980' target=\"_blank\">https://wandb.ai/pirajesh1/hyper/sweeps/y350t980</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/pirajesh1/hyper' target=\"_blank\">https://wandb.ai/pirajesh1/hyper</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/pirajesh1/hyper/sweeps/y350t980' target=\"_blank\">https://wandb.ai/pirajesh1/hyper/sweeps/y350t980</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/pirajesh1/hyper/runs/nu1nsubh' target=\"_blank\">https://wandb.ai/pirajesh1/hyper/runs/nu1nsubh</a>"},"metadata":{}},{"name":"stdout","text":"Ultralytics YOLOv8.2.18 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=/kaggle/working/yellow-4/data.yaml, epochs=25, time=None, patience=50, batch=16, imgsz=800, save=True, save_period=1, cache=False, device=None, workers=8, project=hyper, name=train, exist_ok=True, pretrained=True, optimizer=Adam, verbose=False, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=True, close_mosaic=10, resume=False, amp=False, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=True, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.003739075196324232, lrf=0.001936001342953816, momentum=0.009842836455701677, weight_decay=0.007525843980226237, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=0.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=hyper/train\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n 22        [15, 18, 21]  1   2116435  ultralytics.nn.modules.head.Detect           [1, [128, 256, 512]]          \nModel summary: 225 layers, 11135987 parameters, 11135971 gradients, 28.6 GFLOPs\n\nTransferred 355/355 items from pretrained weights\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir hyper/train', view at http://localhost:6006/\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">winter-sweep-4</strong> at: <a href='https://wandb.ai/pirajesh1/hyper/runs/nu1nsubh' target=\"_blank\">https://wandb.ai/pirajesh1/hyper/runs/nu1nsubh</a><br/> View project at: <a href='https://wandb.ai/pirajesh1/hyper' target=\"_blank\">https://wandb.ai/pirajesh1/hyper</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240521_155304-nu1nsubh/logs</code>"},"metadata":{}},{"name":"stderr","text":"Run nu1nsubh errored:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/agents/pyagent.py\", line 308, in _run_job\n    self._function()\n  File \"/tmp/ipykernel_34/1789913246.py\", line 6, in train\n    results = model.train(data='/kaggle/working/yellow-4/data.yaml',\n  File \"/opt/conda/lib/python3.10/site-packages/ultralytics/engine/model.py\", line 674, in train\n    self.trainer.train()\n  File \"/opt/conda/lib/python3.10/site-packages/ultralytics/engine/trainer.py\", line 199, in train\n    self._do_train(world_size)\n  File \"/opt/conda/lib/python3.10/site-packages/ultralytics/engine/trainer.py\", line 313, in _do_train\n    self._setup_train(world_size)\n  File \"/opt/conda/lib/python3.10/site-packages/ultralytics/engine/trainer.py\", line 228, in _setup_train\n    self.model = self.model.to(self.device)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n    return self._apply(convert)\n  File \"/opt/conda/lib/python3.10/site-packages/ultralytics/nn/tasks.py\", line 232, in _apply\n    self = super()._apply(fn)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n    module._apply(fn)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n    module._apply(fn)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n    module._apply(fn)\n  [Previous line repeated 1 more time]\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n    param_applied = fn(param)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\ntorch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 15.89 GiB of which 22.12 MiB is free. Process 2817 has 15.87 GiB memory in use. Of the allocated memory 15.19 GiB is allocated by PyTorch, and 298.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run nu1nsubh errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/wandb/agents/pyagent.py\", line 308, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_34/1789913246.py\", line 6, in train\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     results = model.train(data='/kaggle/working/yellow-4/data.yaml',\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ultralytics/engine/model.py\", line 674, in train\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self.trainer.train()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ultralytics/engine/trainer.py\", line 199, in train\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._do_train(world_size)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ultralytics/engine/trainer.py\", line 313, in _do_train\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._setup_train(world_size)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ultralytics/engine/trainer.py\", line 228, in _setup_train\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self.model = self.model.to(self.device)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._apply(convert)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ultralytics/nn/tasks.py\", line 232, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self = super()._apply(fn)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     module._apply(fn)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     module._apply(fn)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     module._apply(fn)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   [Previous line repeated 1 more time]\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     param_applied = fn(param)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 15.89 GiB of which 22.12 MiB is free. Process 2817 has 15.87 GiB memory in use. Of the allocated memory 15.19 GiB is allocated by PyTorch, and 298.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: rlqcddwv with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 15\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr0: 0.0032140188777065974\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlrf: 0.006500191672494634\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240521_155330-rlqcddwv</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/pirajesh1/hyper/runs/rlqcddwv' target=\"_blank\">icy-sweep-5</a></strong> to <a href='https://wandb.ai/pirajesh1/hyper' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/pirajesh1/hyper/sweeps/y350t980' target=\"_blank\">https://wandb.ai/pirajesh1/hyper/sweeps/y350t980</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/pirajesh1/hyper' target=\"_blank\">https://wandb.ai/pirajesh1/hyper</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/pirajesh1/hyper/sweeps/y350t980' target=\"_blank\">https://wandb.ai/pirajesh1/hyper/sweeps/y350t980</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/pirajesh1/hyper/runs/rlqcddwv' target=\"_blank\">https://wandb.ai/pirajesh1/hyper/runs/rlqcddwv</a>"},"metadata":{}},{"name":"stdout","text":"Ultralytics YOLOv8.2.18 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=/kaggle/working/yellow-4/data.yaml, epochs=15, time=None, patience=50, batch=32, imgsz=800, save=True, save_period=1, cache=False, device=None, workers=8, project=hyper, name=train, exist_ok=True, pretrained=True, optimizer=Adam, verbose=False, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=True, close_mosaic=10, resume=False, amp=False, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=True, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.0032140188777065974, lrf=0.006500191672494634, momentum=0.009842836455701677, weight_decay=0.007525843980226237, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=0.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=hyper/train\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n 22        [15, 18, 21]  1   2116435  ultralytics.nn.modules.head.Detect           [1, [128, 256, 512]]          \nModel summary: 225 layers, 11135987 parameters, 11135971 gradients, 28.6 GFLOPs\n\nTransferred 355/355 items from pretrained weights\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir hyper/train', view at http://localhost:6006/\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">icy-sweep-5</strong> at: <a href='https://wandb.ai/pirajesh1/hyper/runs/rlqcddwv' target=\"_blank\">https://wandb.ai/pirajesh1/hyper/runs/rlqcddwv</a><br/> View project at: <a href='https://wandb.ai/pirajesh1/hyper' target=\"_blank\">https://wandb.ai/pirajesh1/hyper</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240521_155330-rlqcddwv/logs</code>"},"metadata":{}},{"name":"stderr","text":"Run rlqcddwv errored:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/agents/pyagent.py\", line 308, in _run_job\n    self._function()\n  File \"/tmp/ipykernel_34/1789913246.py\", line 6, in train\n    results = model.train(data='/kaggle/working/yellow-4/data.yaml',\n  File \"/opt/conda/lib/python3.10/site-packages/ultralytics/engine/model.py\", line 674, in train\n    self.trainer.train()\n  File \"/opt/conda/lib/python3.10/site-packages/ultralytics/engine/trainer.py\", line 199, in train\n    self._do_train(world_size)\n  File \"/opt/conda/lib/python3.10/site-packages/ultralytics/engine/trainer.py\", line 313, in _do_train\n    self._setup_train(world_size)\n  File \"/opt/conda/lib/python3.10/site-packages/ultralytics/engine/trainer.py\", line 228, in _setup_train\n    self.model = self.model.to(self.device)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n    return self._apply(convert)\n  File \"/opt/conda/lib/python3.10/site-packages/ultralytics/nn/tasks.py\", line 232, in _apply\n    self = super()._apply(fn)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n    module._apply(fn)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n    module._apply(fn)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n    module._apply(fn)\n  [Previous line repeated 3 more times]\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n    param_applied = fn(param)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\ntorch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 15.89 GiB of which 22.12 MiB is free. Process 2817 has 15.87 GiB memory in use. Of the allocated memory 15.19 GiB is allocated by PyTorch, and 297.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run rlqcddwv errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/wandb/agents/pyagent.py\", line 308, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_34/1789913246.py\", line 6, in train\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     results = model.train(data='/kaggle/working/yellow-4/data.yaml',\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ultralytics/engine/model.py\", line 674, in train\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self.trainer.train()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ultralytics/engine/trainer.py\", line 199, in train\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._do_train(world_size)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ultralytics/engine/trainer.py\", line 313, in _do_train\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._setup_train(world_size)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ultralytics/engine/trainer.py\", line 228, in _setup_train\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self.model = self.model.to(self.device)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._apply(convert)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ultralytics/nn/tasks.py\", line 232, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self = super()._apply(fn)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     module._apply(fn)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     module._apply(fn)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     module._apply(fn)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   [Previous line repeated 3 more times]\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     param_applied = fn(param)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 15.89 GiB of which 22.12 MiB is free. Process 2817 has 15.87 GiB memory in use. Of the allocated memory 15.19 GiB is allocated by PyTorch, and 297.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ha9eyvht with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 15\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr0: 0.002171354628569421\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlrf: 0.006732897001008775\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240521_155356-ha9eyvht</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/pirajesh1/hyper/runs/ha9eyvht' target=\"_blank\">silver-sweep-6</a></strong> to <a href='https://wandb.ai/pirajesh1/hyper' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/pirajesh1/hyper/sweeps/y350t980' target=\"_blank\">https://wandb.ai/pirajesh1/hyper/sweeps/y350t980</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/pirajesh1/hyper' target=\"_blank\">https://wandb.ai/pirajesh1/hyper</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/pirajesh1/hyper/sweeps/y350t980' target=\"_blank\">https://wandb.ai/pirajesh1/hyper/sweeps/y350t980</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/pirajesh1/hyper/runs/ha9eyvht' target=\"_blank\">https://wandb.ai/pirajesh1/hyper/runs/ha9eyvht</a>"},"metadata":{}},{"name":"stdout","text":"Ultralytics YOLOv8.2.18 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=/kaggle/working/yellow-4/data.yaml, epochs=15, time=None, patience=50, batch=16, imgsz=800, save=True, save_period=1, cache=False, device=None, workers=8, project=hyper, name=train, exist_ok=True, pretrained=True, optimizer=Adam, verbose=False, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=True, close_mosaic=10, resume=False, amp=False, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=True, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.002171354628569421, lrf=0.006732897001008775, momentum=0.009842836455701677, weight_decay=0.007525843980226237, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=0.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=hyper/train\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n 22        [15, 18, 21]  1   2116435  ultralytics.nn.modules.head.Detect           [1, [128, 256, 512]]          \nModel summary: 225 layers, 11135987 parameters, 11135971 gradients, 28.6 GFLOPs\n\nTransferred 355/355 items from pretrained weights\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir hyper/train', view at http://localhost:6006/\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">silver-sweep-6</strong> at: <a href='https://wandb.ai/pirajesh1/hyper/runs/ha9eyvht' target=\"_blank\">https://wandb.ai/pirajesh1/hyper/runs/ha9eyvht</a><br/> View project at: <a href='https://wandb.ai/pirajesh1/hyper' target=\"_blank\">https://wandb.ai/pirajesh1/hyper</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240521_155356-ha9eyvht/logs</code>"},"metadata":{}},{"name":"stderr","text":"Run ha9eyvht errored:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/agents/pyagent.py\", line 308, in _run_job\n    self._function()\n  File \"/tmp/ipykernel_34/1789913246.py\", line 6, in train\n    results = model.train(data='/kaggle/working/yellow-4/data.yaml',\n  File \"/opt/conda/lib/python3.10/site-packages/ultralytics/engine/model.py\", line 674, in train\n    self.trainer.train()\n  File \"/opt/conda/lib/python3.10/site-packages/ultralytics/engine/trainer.py\", line 199, in train\n    self._do_train(world_size)\n  File \"/opt/conda/lib/python3.10/site-packages/ultralytics/engine/trainer.py\", line 313, in _do_train\n    self._setup_train(world_size)\n  File \"/opt/conda/lib/python3.10/site-packages/ultralytics/engine/trainer.py\", line 228, in _setup_train\n    self.model = self.model.to(self.device)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n    return self._apply(convert)\n  File \"/opt/conda/lib/python3.10/site-packages/ultralytics/nn/tasks.py\", line 232, in _apply\n    self = super()._apply(fn)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n    module._apply(fn)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n    module._apply(fn)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n    module._apply(fn)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n    param_applied = fn(param)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\ntorch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 15.89 GiB of which 22.12 MiB is free. Process 2817 has 15.87 GiB memory in use. Of the allocated memory 15.19 GiB is allocated by PyTorch, and 297.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run ha9eyvht errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/wandb/agents/pyagent.py\", line 308, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_34/1789913246.py\", line 6, in train\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     results = model.train(data='/kaggle/working/yellow-4/data.yaml',\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ultralytics/engine/model.py\", line 674, in train\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self.trainer.train()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ultralytics/engine/trainer.py\", line 199, in train\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._do_train(world_size)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ultralytics/engine/trainer.py\", line 313, in _do_train\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._setup_train(world_size)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ultralytics/engine/trainer.py\", line 228, in _setup_train\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self.model = self.model.to(self.device)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._apply(convert)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ultralytics/nn/tasks.py\", line 232, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self = super()._apply(fn)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     module._apply(fn)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     module._apply(fn)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     module._apply(fn)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     param_applied = fn(param)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 15.89 GiB of which 22.12 MiB is free. Process 2817 has 15.87 GiB memory in use. Of the allocated memory 15.19 GiB is allocated by PyTorch, and 297.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: qg0w76w4 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 25\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr0: 0.004516412441611292\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlrf: 0.0033841907010748904\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240521_155422-qg0w76w4</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/pirajesh1/hyper/runs/qg0w76w4' target=\"_blank\">dauntless-sweep-7</a></strong> to <a href='https://wandb.ai/pirajesh1/hyper' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/pirajesh1/hyper/sweeps/y350t980' target=\"_blank\">https://wandb.ai/pirajesh1/hyper/sweeps/y350t980</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/pirajesh1/hyper' target=\"_blank\">https://wandb.ai/pirajesh1/hyper</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/pirajesh1/hyper/sweeps/y350t980' target=\"_blank\">https://wandb.ai/pirajesh1/hyper/sweeps/y350t980</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/pirajesh1/hyper/runs/qg0w76w4' target=\"_blank\">https://wandb.ai/pirajesh1/hyper/runs/qg0w76w4</a>"},"metadata":{}},{"name":"stdout","text":"Ultralytics YOLOv8.2.18 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=/kaggle/working/yellow-4/data.yaml, epochs=25, time=None, patience=50, batch=16, imgsz=800, save=True, save_period=1, cache=False, device=None, workers=8, project=hyper, name=train, exist_ok=True, pretrained=True, optimizer=Adam, verbose=False, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=True, close_mosaic=10, resume=False, amp=False, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=True, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.004516412441611292, lrf=0.0033841907010748904, momentum=0.009842836455701677, weight_decay=0.007525843980226237, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=0.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=hyper/train\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n 22        [15, 18, 21]  1   2116435  ultralytics.nn.modules.head.Detect           [1, [128, 256, 512]]          \nModel summary: 225 layers, 11135987 parameters, 11135971 gradients, 28.6 GFLOPs\n\nTransferred 355/355 items from pretrained weights\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir hyper/train', view at http://localhost:6006/\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">dauntless-sweep-7</strong> at: <a href='https://wandb.ai/pirajesh1/hyper/runs/qg0w76w4' target=\"_blank\">https://wandb.ai/pirajesh1/hyper/runs/qg0w76w4</a><br/> View project at: <a href='https://wandb.ai/pirajesh1/hyper' target=\"_blank\">https://wandb.ai/pirajesh1/hyper</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240521_155422-qg0w76w4/logs</code>"},"metadata":{}},{"name":"stderr","text":"Run qg0w76w4 errored:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/agents/pyagent.py\", line 308, in _run_job\n    self._function()\n  File \"/tmp/ipykernel_34/1789913246.py\", line 6, in train\n    results = model.train(data='/kaggle/working/yellow-4/data.yaml',\n  File \"/opt/conda/lib/python3.10/site-packages/ultralytics/engine/model.py\", line 674, in train\n    self.trainer.train()\n  File \"/opt/conda/lib/python3.10/site-packages/ultralytics/engine/trainer.py\", line 199, in train\n    self._do_train(world_size)\n  File \"/opt/conda/lib/python3.10/site-packages/ultralytics/engine/trainer.py\", line 313, in _do_train\n    self._setup_train(world_size)\n  File \"/opt/conda/lib/python3.10/site-packages/ultralytics/engine/trainer.py\", line 228, in _setup_train\n    self.model = self.model.to(self.device)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n    return self._apply(convert)\n  File \"/opt/conda/lib/python3.10/site-packages/ultralytics/nn/tasks.py\", line 232, in _apply\n    self = super()._apply(fn)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n    module._apply(fn)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n    module._apply(fn)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n    module._apply(fn)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n    param_applied = fn(param)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\ntorch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 15.89 GiB of which 22.12 MiB is free. Process 2817 has 15.87 GiB memory in use. Of the allocated memory 15.19 GiB is allocated by PyTorch, and 297.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run qg0w76w4 errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/wandb/agents/pyagent.py\", line 308, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_34/1789913246.py\", line 6, in train\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     results = model.train(data='/kaggle/working/yellow-4/data.yaml',\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ultralytics/engine/model.py\", line 674, in train\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self.trainer.train()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ultralytics/engine/trainer.py\", line 199, in train\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._do_train(world_size)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ultralytics/engine/trainer.py\", line 313, in _do_train\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._setup_train(world_size)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ultralytics/engine/trainer.py\", line 228, in _setup_train\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self.model = self.model.to(self.device)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._apply(convert)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ultralytics/nn/tasks.py\", line 232, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self = super()._apply(fn)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     module._apply(fn)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     module._apply(fn)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     module._apply(fn)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     param_applied = fn(param)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 15.89 GiB of which 22.12 MiB is free. Process 2817 has 15.87 GiB memory in use. Of the allocated memory 15.19 GiB is allocated by PyTorch, and 297.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ja0cyk1v with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 15\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr0: 0.003304613880767311\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlrf: 0.004052382678192856\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240521_155448-ja0cyk1v</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/pirajesh1/hyper/runs/ja0cyk1v' target=\"_blank\">dazzling-sweep-8</a></strong> to <a href='https://wandb.ai/pirajesh1/hyper' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/pirajesh1/hyper/sweeps/y350t980' target=\"_blank\">https://wandb.ai/pirajesh1/hyper/sweeps/y350t980</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/pirajesh1/hyper' target=\"_blank\">https://wandb.ai/pirajesh1/hyper</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/pirajesh1/hyper/sweeps/y350t980' target=\"_blank\">https://wandb.ai/pirajesh1/hyper/sweeps/y350t980</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/pirajesh1/hyper/runs/ja0cyk1v' target=\"_blank\">https://wandb.ai/pirajesh1/hyper/runs/ja0cyk1v</a>"},"metadata":{}},{"name":"stdout","text":"Ultralytics YOLOv8.2.18 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=/kaggle/working/yellow-4/data.yaml, epochs=15, time=None, patience=50, batch=32, imgsz=800, save=True, save_period=1, cache=False, device=None, workers=8, project=hyper, name=train, exist_ok=True, pretrained=True, optimizer=Adam, verbose=False, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=True, close_mosaic=10, resume=False, amp=False, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=True, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.003304613880767311, lrf=0.004052382678192856, momentum=0.009842836455701677, weight_decay=0.007525843980226237, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=0.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=hyper/train\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n 22        [15, 18, 21]  1   2116435  ultralytics.nn.modules.head.Detect           [1, [128, 256, 512]]          \nModel summary: 225 layers, 11135987 parameters, 11135971 gradients, 28.6 GFLOPs\n\nTransferred 355/355 items from pretrained weights\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir hyper/train', view at http://localhost:6006/\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">dazzling-sweep-8</strong> at: <a href='https://wandb.ai/pirajesh1/hyper/runs/ja0cyk1v' target=\"_blank\">https://wandb.ai/pirajesh1/hyper/runs/ja0cyk1v</a><br/> View project at: <a href='https://wandb.ai/pirajesh1/hyper' target=\"_blank\">https://wandb.ai/pirajesh1/hyper</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240521_155448-ja0cyk1v/logs</code>"},"metadata":{}},{"name":"stderr","text":"Run ja0cyk1v errored:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/agents/pyagent.py\", line 308, in _run_job\n    self._function()\n  File \"/tmp/ipykernel_34/1789913246.py\", line 6, in train\n    results = model.train(data='/kaggle/working/yellow-4/data.yaml',\n  File \"/opt/conda/lib/python3.10/site-packages/ultralytics/engine/model.py\", line 674, in train\n    self.trainer.train()\n  File \"/opt/conda/lib/python3.10/site-packages/ultralytics/engine/trainer.py\", line 199, in train\n    self._do_train(world_size)\n  File \"/opt/conda/lib/python3.10/site-packages/ultralytics/engine/trainer.py\", line 313, in _do_train\n    self._setup_train(world_size)\n  File \"/opt/conda/lib/python3.10/site-packages/ultralytics/engine/trainer.py\", line 228, in _setup_train\n    self.model = self.model.to(self.device)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n    return self._apply(convert)\n  File \"/opt/conda/lib/python3.10/site-packages/ultralytics/nn/tasks.py\", line 232, in _apply\n    self = super()._apply(fn)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n    module._apply(fn)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n    module._apply(fn)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n    module._apply(fn)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n    param_applied = fn(param)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\ntorch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 15.89 GiB of which 22.12 MiB is free. Process 2817 has 15.87 GiB memory in use. Of the allocated memory 15.19 GiB is allocated by PyTorch, and 297.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run ja0cyk1v errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/wandb/agents/pyagent.py\", line 308, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_34/1789913246.py\", line 6, in train\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     results = model.train(data='/kaggle/working/yellow-4/data.yaml',\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ultralytics/engine/model.py\", line 674, in train\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self.trainer.train()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ultralytics/engine/trainer.py\", line 199, in train\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._do_train(world_size)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ultralytics/engine/trainer.py\", line 313, in _do_train\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._setup_train(world_size)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ultralytics/engine/trainer.py\", line 228, in _setup_train\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self.model = self.model.to(self.device)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._apply(convert)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ultralytics/nn/tasks.py\", line 232, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self = super()._apply(fn)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     module._apply(fn)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     module._apply(fn)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     module._apply(fn)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     param_applied = fn(param)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 15.89 GiB of which 22.12 MiB is free. Process 2817 has 15.87 GiB memory in use. Of the allocated memory 15.19 GiB is allocated by PyTorch, and 297.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1afibxyv with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 15\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr0: 0.000719766657037533\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlrf: 0.003552585840486143\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240521_155523-1afibxyv</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/pirajesh1/hyper/runs/1afibxyv' target=\"_blank\">scarlet-sweep-9</a></strong> to <a href='https://wandb.ai/pirajesh1/hyper' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/pirajesh1/hyper/sweeps/y350t980' target=\"_blank\">https://wandb.ai/pirajesh1/hyper/sweeps/y350t980</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/pirajesh1/hyper' target=\"_blank\">https://wandb.ai/pirajesh1/hyper</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/pirajesh1/hyper/sweeps/y350t980' target=\"_blank\">https://wandb.ai/pirajesh1/hyper/sweeps/y350t980</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/pirajesh1/hyper/runs/1afibxyv' target=\"_blank\">https://wandb.ai/pirajesh1/hyper/runs/1afibxyv</a>"},"metadata":{}},{"name":"stdout","text":"Ultralytics YOLOv8.2.18 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=/kaggle/working/yellow-4/data.yaml, epochs=15, time=None, patience=50, batch=32, imgsz=800, save=True, save_period=1, cache=False, device=None, workers=8, project=hyper, name=train, exist_ok=True, pretrained=True, optimizer=Adam, verbose=False, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=True, close_mosaic=10, resume=False, amp=False, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=True, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.000719766657037533, lrf=0.003552585840486143, momentum=0.009842836455701677, weight_decay=0.007525843980226237, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=0.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=hyper/train\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n 22        [15, 18, 21]  1   2116435  ultralytics.nn.modules.head.Detect           [1, [128, 256, 512]]          \nModel summary: 225 layers, 11135987 parameters, 11135971 gradients, 28.6 GFLOPs\n\nTransferred 355/355 items from pretrained weights\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir hyper/train', view at http://localhost:6006/\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">scarlet-sweep-9</strong> at: <a href='https://wandb.ai/pirajesh1/hyper/runs/1afibxyv' target=\"_blank\">https://wandb.ai/pirajesh1/hyper/runs/1afibxyv</a><br/> View project at: <a href='https://wandb.ai/pirajesh1/hyper' target=\"_blank\">https://wandb.ai/pirajesh1/hyper</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240521_155523-1afibxyv/logs</code>"},"metadata":{}},{"name":"stderr","text":"Run 1afibxyv errored:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/agents/pyagent.py\", line 308, in _run_job\n    self._function()\n  File \"/tmp/ipykernel_34/1789913246.py\", line 6, in train\n    results = model.train(data='/kaggle/working/yellow-4/data.yaml',\n  File \"/opt/conda/lib/python3.10/site-packages/ultralytics/engine/model.py\", line 674, in train\n    self.trainer.train()\n  File \"/opt/conda/lib/python3.10/site-packages/ultralytics/engine/trainer.py\", line 199, in train\n    self._do_train(world_size)\n  File \"/opt/conda/lib/python3.10/site-packages/ultralytics/engine/trainer.py\", line 313, in _do_train\n    self._setup_train(world_size)\n  File \"/opt/conda/lib/python3.10/site-packages/ultralytics/engine/trainer.py\", line 228, in _setup_train\n    self.model = self.model.to(self.device)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n    return self._apply(convert)\n  File \"/opt/conda/lib/python3.10/site-packages/ultralytics/nn/tasks.py\", line 232, in _apply\n    self = super()._apply(fn)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n    module._apply(fn)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n    module._apply(fn)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n    module._apply(fn)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n    param_applied = fn(param)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\ntorch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 15.89 GiB of which 22.12 MiB is free. Process 2817 has 15.87 GiB memory in use. Of the allocated memory 15.19 GiB is allocated by PyTorch, and 297.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 1afibxyv errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/wandb/agents/pyagent.py\", line 308, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_34/1789913246.py\", line 6, in train\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     results = model.train(data='/kaggle/working/yellow-4/data.yaml',\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ultralytics/engine/model.py\", line 674, in train\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self.trainer.train()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ultralytics/engine/trainer.py\", line 199, in train\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._do_train(world_size)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ultralytics/engine/trainer.py\", line 313, in _do_train\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._setup_train(world_size)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ultralytics/engine/trainer.py\", line 228, in _setup_train\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self.model = self.model.to(self.device)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in to\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._apply(convert)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ultralytics/nn/tasks.py\", line 232, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self = super()._apply(fn)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     module._apply(fn)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     module._apply(fn)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 810, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     module._apply(fn)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 833, in _apply\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     param_applied = fn(param)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1158, in convert\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 15.89 GiB of which 22.12 MiB is free. Process 2817 has 15.87 GiB memory in use. Of the allocated memory 15.19 GiB is allocated by PyTorch, and 297.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ehdqg4kl with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr0: 0.00398749850942998\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlrf: 0.007488670844834261\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240521_155550-ehdqg4kl</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/pirajesh1/hyper/runs/ehdqg4kl' target=\"_blank\">logical-sweep-10</a></strong> to <a href='https://wandb.ai/pirajesh1/hyper' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/pirajesh1/hyper/sweeps/y350t980' target=\"_blank\">https://wandb.ai/pirajesh1/hyper/sweeps/y350t980</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/pirajesh1/hyper' target=\"_blank\">https://wandb.ai/pirajesh1/hyper</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/pirajesh1/hyper/sweeps/y350t980' target=\"_blank\">https://wandb.ai/pirajesh1/hyper/sweeps/y350t980</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/pirajesh1/hyper/runs/ehdqg4kl' target=\"_blank\">https://wandb.ai/pirajesh1/hyper/runs/ehdqg4kl</a>"},"metadata":{}},{"name":"stdout","text":"Ultralytics YOLOv8.2.18 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=/kaggle/working/yellow-4/data.yaml, epochs=5, time=None, patience=50, batch=32, imgsz=800, save=True, save_period=1, cache=False, device=None, workers=8, project=hyper, name=train, exist_ok=True, pretrained=True, optimizer=Adam, verbose=False, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=True, close_mosaic=10, resume=False, amp=False, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=True, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.00398749850942998, lrf=0.007488670844834261, momentum=0.009842836455701677, weight_decay=0.007525843980226237, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=0.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=hyper/train\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n 22        [15, 18, 21]  1   2116435  ultralytics.nn.modules.head.Detect           [1, [128, 256, 512]]          \nModel summary: 225 layers, 11135987 parameters, 11135971 gradients, 28.6 GFLOPs\n\nTransferred 355/355 items from pretrained weights\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir hyper/train', view at http://localhost:6006/\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">logical-sweep-10</strong> at: <a href='https://wandb.ai/pirajesh1/hyper/runs/ehdqg4kl' target=\"_blank\">https://wandb.ai/pirajesh1/hyper/runs/ehdqg4kl</a><br/> View project at: <a href='https://wandb.ai/pirajesh1/hyper' target=\"_blank\">https://wandb.ai/pirajesh1/hyper</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240521_155550-ehdqg4kl/logs</code>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}